{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import keras\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2,time\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Activation,Conv2D,MaxPooling2D,Flatten,Dropout,BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"C:\\\\Users\\\\Bhavesh\\\\Documents\\\\snapchat_filter\\\\weights.4C_F_3D.200.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Bhavesh\\\\Downloads\\\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732\n"
     ]
    }
   ],
   "source": [
    "video=cv2.VideoCapture(0)\n",
    "d=1\n",
    "g=0\n",
    "while True:\n",
    "    d=d+1\n",
    "    g=0\n",
    "    check,frame=video.read()\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(gray_frame,1.5,5)\n",
    "    for x,y,w,h in faces:\n",
    "        crop_img = frame[y:y+h, x:x+w]\n",
    "        img = gray_frame[y:y+h,x:x+w]\n",
    "        g=1\n",
    "    if g==1:\n",
    "        img=cv2.resize(img,(96,96))#,Image.ANTIALIAS)\n",
    "        test_img=np.array(img)/255\n",
    "        test_img = np.reshape(test_img, (1,96,96,1))    # Model input shape = [batch_size, height, width, no. of channels]\n",
    "        key_prediction = model.predict(test_img)      # shape = [batch_size, values]\n",
    "        c=np.reshape(key_prediction,(15,2))\n",
    "        a=x+(c[:,0]+0.5)*w\n",
    "        b=y+(c[:,1]+0.5)*h\n",
    "        a=a.astype(int)\n",
    "        b=b.astype(int)\n",
    "        frame[b,a]=[255,255,255]\n",
    "    ##     FILTER-GLASS    #####\n",
    "        glass=cv2.imread(\"C:\\\\Users\\\\Bhavesh\\\\Desktop\\\\glass.png\")\n",
    "        glass_width=(a[5]-a[3])*1.2\n",
    "        glass_height=glass_width/4\n",
    "        glass_width=glass_width.astype(int)\n",
    "        glass_height=glass_height.astype(int)\n",
    "        top_left=(a[3],b[3])                \n",
    "        bottom_right=(a[5]+glass_width,b[5]+glass_height)             \n",
    "        glass = cv2.resize(glass, (glass_width,glass_height))                                #ACTUAL GLASS LOADED FROM THE DISK\n",
    "        glass_gray=cv2.cvtColor(glass,cv2.COLOR_BGR2GRAY)\n",
    "        _,glass_mask= cv2.threshold(glass_gray,25,255,cv2.THRESH_BINARY_INV)\n",
    "        area=frame[top_left[1]:top_left[1]+glass_height,top_left[0]:top_left[0]+glass_width] #AREA WHERE GLASS IS TO BE PLACED\n",
    "        area_no_glass=cv2.bitwise_and(area,area,mask=glass_mask)\n",
    "        final=cv2.add(area_no_glass,glass)\n",
    "    \n",
    "        frame[top_left[1]:top_left[1]+glass_height,top_left[0]:top_left[0]+glass_width]=final\n",
    "    #gw,gh,gc = glass.shape\n",
    "    #for i in range(0,gw):       # Overlay the filter based on the alpha channel\n",
    "     #          for j in range(0,gh):\n",
    "      #              if glass[i,j][3] != 0:\n",
    "    #                   crop_img[brow_coords[1]+j-50,left_eye_coords[0]+i-90] = glass[i,j][:3]###############3\n",
    "    ###############################\n",
    "    cv2.imshow(\"pls\",frame)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "print(d)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[318 383 329 306 372 395 334 295 365 406 354 328 381 354 355]\n",
      "[145 141 145 147 143 142 127 130 126 124 180 215 212 207 225]\n",
      "106\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(glass_width)\n",
    "print(glass_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "293\n",
      "-82.85714285714286\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "print(a[5])\n",
    "print(a[3])\n",
    "print(glass_width/1.4)\n",
    "print(a[5]-a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
